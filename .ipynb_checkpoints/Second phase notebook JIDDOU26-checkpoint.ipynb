{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6117e80a-8869-47fa-bdae-f7e86c4fa8fa",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "<h1 style=\"font-family:Bahnschrift Condensed;text-align:center; font-size:240%;\">2024 National Data Science Competition by RIMAI: License Plate Recognition in Mauritania - Data Science Phase</h1>\n",
    "<h style=\"font-family:Bahnschrift Condensed;text-align:center; font-size:240%;\">2024 National Data Science Competition by RIMAI: License Plate Recognition in Mauritania - Data Science Phase</h2>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://www.rim-ai.com/assets/logo.png\" style=\"width:30%; height:auto;\" alt=\"Logo RIM AI\">\n",
    "</div>\n",
    "\n",
    "- **El Moustapha Cheikh Jiddou** \n",
    "- **Pseudo: Jiddou26**\n",
    "- **Email:** elmoustapha.cheikh.jiddou@gmail.com\n",
    "\n",
    "<p style=\"font-family:Bahnschrift Condensed;font-size:120%; text-align:justify;\">\n",
    "    The second phase of the 2024 National Data Science Competition by RIMAI shifts the focus to the heart of the challenge: data science. After gathering diverse and high-quality images in the first phase, this stage is dedicated to developing and fine-tuning algorithms for the automatic recognition of Mauritanian license plates.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:120%; text-align:justify;\">\n",
    "    Participants are invited to leverage their data science skills to create robust models capable of accurately identifying and reading license plates under various conditions. This phase is crucial, as it will test the effectiveness of the algorithms in real-world scenarios, pushing the boundaries of AI and machine learning in the context of Mauritanian license plate recognition.\n",
    "</p>\n",
    "<p style=\"font-size:120%; text-align:justify;\">\n",
    "    The competition aims to drive innovation in computer vision, with a particular emphasis on enhancing the accuracy, efficiency, and scalability of the solutions. The challenge is designed not only to assess technical prowess but also to encourage creativity in overcoming the unique challenges presented by this application.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d29537-3def-43c9-a6d2-307b4657b4c6",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 1: Importing Necessary Libraries</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6326c5db-51ef-491a-9eec-678acca2d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from easyocr import Reader\n",
    "import pytesseract\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6ca52-51a7-41c9-9636-a0cc9e5bd2c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 2: License Plate Detection and Transformation Functions</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74ccf9ec-135a-490e-8210-87d6c0a2bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de détection de plaque d'immatriculation\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5285497-a637-4365-91f3-7ed1090ab26b",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 3: Processing and Annotating Images</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efce19ad-0825-4081-9093-ff5efb043881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(image_path, output_dir):\n",
    "    # Charger l'image\n",
    "    car = cv2.imread(image_path)\n",
    "    # Convertir en niveau de gris\n",
    "    gray = cv2.cvtColor(car, cv2.COLOR_BGR2GRAY)\n",
    "    # Appliquer un flou gaussien\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # Détecter les contours\n",
    "    edged = cv2.Canny(blur, 50, 200)\n",
    "    # Trouver les contours les plus grands\n",
    "    cont, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cont = sorted(cont, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    plate_cnt = None\n",
    "    for c in cont:\n",
    "        arc = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * arc, True)\n",
    "        if len(approx) == 4:\n",
    "            plate_cnt = approx\n",
    "            break\n",
    "\n",
    "    if plate_cnt is None:\n",
    "        print(f\"No license plate detected in {image_path}.\")\n",
    "        return None\n",
    "\n",
    "    # Redresser la plaque d'immatriculation\n",
    "    warped_plate = four_point_transform(gray, plate_cnt.reshape(4, 2))\n",
    "\n",
    "    # Redimensionner la plaque pour améliorer la précision de l'OCR\n",
    "    plate = cv2.resize(warped_plate, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Utiliser EasyOCR pour reconnaître les caractères de la plaque\n",
    "    reader = Reader(['en'])\n",
    "    detection = reader.readtext(plate)\n",
    "\n",
    "    if len(detection) == 0:\n",
    "        print(f\"Unable to read license plate text in {image_path}.\")\n",
    "        return None\n",
    "\n",
    "    # Extraire le texte reconnu\n",
    "    text = detection[0][1]\n",
    "\n",
    "    # Filtrer pour obtenir uniquement les lettres et les chiffres\n",
    "    filtered_text = ''.join([c for c in text if c.isalnum()])\n",
    "\n",
    "    # Nommer l'image avec le numéro de plaque d'immatriculation\n",
    "    output_filename = os.path.join(output_dir, f'{filtered_text}.jpg')\n",
    "\n",
    "    # Sauvegarder l'image annotée\n",
    "    cv2.imwrite(output_filename, car)\n",
    "\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b266e3e-afdd-4d15-82b3-40002e516a9f",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 4: Processing Images in Folders</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccef06c7-b71f-40ae-81cd-d93a77f0b0a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'data_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m data_mat_train_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_mat_train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(data_mat_train_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_train_dir):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      7\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_train_dir, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'data_train'"
     ]
    }
   ],
   "source": [
    "data_train_dir = \"data_train\"\n",
    "data_mat_train_dir = \"data_mat_train\"\n",
    "os.makedirs(data_mat_train_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(data_train_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(data_train_dir, filename)\n",
    "        output_filename = process_single_image(image_path, data_mat_train_dir)\n",
    "        if output_filename:\n",
    "            print(f\"Processed: {filename} -> Saved as: {output_filename}\")\n",
    "        else:\n",
    "            print(f\"Processed: {filename} -> No license plate detected or unable to read text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8095440-0781-4129-b579-a908aec226d6",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 5: Loading Data and Labels</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303fac-2839-41a8-8ea6-8fddaf22f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img_path = os.path.join(data_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:  # Vérifier si l'image est valide\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (128, 128))  # Redimensionner les images\n",
    "            images.append(img)\n",
    "            # Extraire l'étiquette à partir du nom du fichier\n",
    "            label = filename.split('_')[0]  \n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "train_dir = 'data_mat_train'\n",
    "test_dir = 'data_mat_test'\n",
    "\n",
    "X_train, y_train = load_data_and_labels(train_dir)\n",
    "X_test, y_test = load_data_and_labels(test_dir)\n",
    "\n",
    "# Normaliser les images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6aaa4f-b3dc-486d-bfd9-fc6b310c0c9e",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 6: Building and Training the CNN Model</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3fd2a-a05d-4804-9681-2fba50834542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bae988-fa50-4f4f-9789-b6fba7b512f6",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 7: Evaluating the Model</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5cea1-772c-4ba4-8c1e-da4e8b14843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des étiquettes d'entraînement\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Création d'un dictionnaire des étiquettes d'entraînement\n",
    "train_labels_set = set(y_train)\n",
    "\n",
    "# Filtrer les données de test pour inclure uniquement les étiquettes présentes dans les données d'entraînement\n",
    "filtered_indices = [i for i, label in enumerate(y_test) if label in train_labels_set]\n",
    "X_test_filtered = X_test[filtered_indices]\n",
    "y_test_filtered = y_test[filtered_indices]\n",
    "\n",
    "# Encoder les étiquettes de test filtrées\n",
    "y_test_encoded = label_encoder.transform(y_test_filtered)\n",
    "\n",
    "# Conversion des étiquettes en one-hot encoding\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "y_train_one_hot = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_one_hot = to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle sur les données de test filtrées\n",
    "loss, accuracy = model.evaluate(X_test_filtered, y_test_one-hot)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3bd86-e287-445e-a0a4-59c83ce43448",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 8: Testing the Model on a Single Image</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8c191-d92b-4b11-8603-599889902537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger votre image\n",
    "image_path = 'DataChallenge.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Assurez-vous que l'image est en format RGB\n",
    "image = cv2.resize(image, (128, 128))  # Redimensionnez l'image à la taille d'entrée du modèle\n",
    "\n",
    "# Normaliser l'image\n",
    "image = image / 255.0\n",
    "\n",
    "# Faire une prédiction\n",
    "prediction = model.predict(np.expand_dims(image, axis=0))\n",
    "\n",
    "# Convertir les probabilités en étiquettes\n",
    "predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "\n",
    "print(f'Predicted label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e8e37-a6cb-4bcd-b62a-df49166c6c2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div align=\"center\"><span style=\"font-family:Bahnschrift Condensed;font-size:40px\"><b>Section 9: Advanced License Plate Detection and Visualization</b></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfeb37-22d9-49ee-8833-415308f66ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # Calculer les largeurs et hauteurs des côtés du rectangle\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # Destination points for perspective transform\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    # Compute the perspective transform matrix and apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    return warped\n",
    "\n",
    "def process_single_image(image_path, output_path):\n",
    "    reader = Reader(['en'], gpu=False, verbose=False)\n",
    "    \n",
    "    car = cv2.imread(image_path)\n",
    "    car = cv2.resize(car, (800, 600))\n",
    "    gray = cv2.cvtColor(car, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(blur, 50, 200)\n",
    "    cont, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cont = sorted(cont, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    plate_cnt = None\n",
    "    for c in cont:\n",
    "        arc = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * arc, True)\n",
    "        if len(approx) == 4:\n",
    "            plate_cnt = approx\n",
    "            break\n",
    "\n",
    "    if plate_cnt is None:\n",
    "        print(\"No license plate detected.\")\n",
    "        return\n",
    "\n",
    "    # Redresser la plaque d'immatriculation\n",
    "    warped_plate = four_point_transform(gray, plate_cnt.reshape(4, 2))\n",
    "\n",
    "    # Redimensionner la plaque pour améliorer la précision de l'OCR\n",
    "    plate = cv2.resize(warped_plate, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Appliquer une égalisation de l'histogramme pour améliorer le contraste\n",
    "    plate = cv2.equalizeHist(plate)\n",
    "\n",
    "    # Filtrage morphologique pour améliorer les contours des caractères\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    plate = cv2.morphologyEx(plate, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Utiliser EasyOCR pour reconnaître les caractères\n",
    "    detection = reader.readtext(plate)\n",
    "    print(detection)\n",
    "\n",
    "    if len(detection) == 0:\n",
    "        text = \"Impossible de lire le texte de la plaque d'immatriculation\"\n",
    "        cv2.putText(car, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 3)\n",
    "    else:\n",
    "        # Extraire le texte reconnu\n",
    "        text = detection[0][1]\n",
    "        # Filtrer pour obtenir uniquement les lettres et les chiffres\n",
    "        filtered_text = ''.join([c for c in text if c.isalnum()])\n",
    "        if len(filtered_text) > 8:\n",
    "            filtered_text = filtered_text[:8]\n",
    "        cv2.drawContours(car, [plate_cnt], -1, (0, 255, 0), 3)\n",
    "        display_text = f\"{filtered_text} ({detection[0][2] * 100:.2f}%)\"\n",
    "        cv2.putText(car, display_text, (plate_cnt[0][0][0], plate_cnt[0][0][1] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        print(display_text)\n",
    "\n",
    "    # Sauvegarder l'image annotée\n",
    "    cv2.imwrite(output_path, car)\n",
    "    # Sauvegarder l'image de la plaque redressée\n",
    "    cv2.imwrite('warped_plate.jpg', plate)\n",
    "\n",
    "# Tester avec une seule image\n",
    "process_single_image('hamada.jpg', 'annotated_test.jpg')\n",
    "\n",
    "# Afficher les images avec matplotlib\n",
    "annotated_image = cv2.imread('annotated_test.jpg')\n",
    "warped_plate = cv2.imread('warped_plate.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(warped_plate, cmap='gray')\n",
    "plt.title('Plaque d\\'immatriculation')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image avec détection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
